# 07 - Fonctionnalit√©s IA

> **Objectif** : Sp√©cifier toutes les int√©grations IA (chat, RAG, g√©n√©ration)
> **Sources** : `blaizbot-wireframe/js/modules/ai-assistant.js`, `lab.js`, `chat.js`

---

## üéØ Vue d'ensemble

BlaizBot int√®gre 3 types de fonctionnalit√©s IA :

| Type | Module | Usage |
| :--- | :--- | :--- |
| **Chat conversationnel** | Assistant IA | Aide aux devoirs, r√©visions |
| **RAG (Retrieval)** | Base de connaissances | R√©ponses bas√©es sur les cours |
| **G√©n√©ration** | Blaiz'Lab | Fiches, quiz, contenus |

---

## ü§ñ Assistant IA (√âl√®ve)

### Comportement attendu

L'assistant Blaiz'bot aide l'√©l√®ve dans ses devoirs et r√©visions :

1. **Contexte** : Se base sur la mati√®re et le th√®me s√©lectionn√©s
2. **Sources** : Utilise les documents upload√©s (RAG)
3. **P√©dagogie** : R√©pond de mani√®re adapt√©e au niveau scolaire
4. **Citations** : Cite les sources utilis√©es pour la r√©ponse

### Flux de donn√©es

```
√âl√®ve ‚Üí Question + (Mati√®re + Th√®me + Documents)
           ‚Üì
    [Embeddings des documents]
           ‚Üì
    [Recherche vectorielle]
           ‚Üì
    [Contexte pertinent]
           ‚Üì
    [Prompt syst√®me + Contexte + Question]
           ‚Üì
    OpenAI GPT-4o-mini
           ‚Üì
    R√©ponse + Sources cit√©es
```

### API

```typescript
// POST /api/ai/chat
interface ChatRequest {
  message: string;
  context: {
    subjectId: string;      // Ex: "maths"
    themeId?: string;       // Ex: "fractions"
    documentIds?: string[]; // Documents sources
  };
  conversationId?: string;  // Pour l'historique
}

interface ChatResponse {
  message: string;
  sources: {
    documentId: string;
    documentName: string;
    excerpt: string;
    relevance: number; // 0-1
  }[];
  conversationId: string;
}
```

### Prompt syst√®me (√âl√®ve)

```
Tu es Blaiz'bot, un assistant p√©dagogique pour les √©l√®ves de coll√®ge.

R√àGLES :
1. R√©ponds de mani√®re claire et adapt√©e au niveau coll√®ge
2. Utilise des exemples concrets pour expliquer
3. Si tu utilises des informations des documents fournis, cite la source
4. Si tu ne sais pas, dis-le clairement
5. Encourage l'√©l√®ve √† r√©fl√©chir plut√¥t que donner directement la r√©ponse
6. Utilise le format Markdown pour structurer tes r√©ponses

CONTEXTE ACTUEL :
- Mati√®re : {subject}
- Th√®me : {theme}
- Documents disponibles : {documents}

HISTORIQUE DE CONVERSATION :
{history}
```

---

## üî¨ Blaiz'Lab (G√©n√©ration)

### Fonctionnalit√©s

| Action | Description | Input | Output |
| :--- | :--- | :--- | :--- |
| **R√©sumer** | Synth√®se d'un document | Document PDF/texte | R√©sum√© structur√© |
| **Fiche r√©vision** | Fiche m√©mo | Th√®me + Sources | Fiche format√©e |
| **Quiz** | Questions de r√©vision | Th√®me + Sources | Quiz interactif |
| **Plan** | Structure de cours/expos√© | Sujet | Plan d√©taill√© |
| **Expliquer** | Simplification | Concept complexe | Explication claire |

### API G√©n√©ration

```typescript
// POST /api/ai/generate
interface GenerateRequest {
  type: 'summary' | 'revision' | 'quiz' | 'plan' | 'explain';
  input: {
    text?: string;          // Texte brut
    documentIds?: string[]; // Documents sources
    topic?: string;         // Sujet/th√®me
  };
  options?: {
    length?: 'short' | 'medium' | 'long';
    format?: 'markdown' | 'html' | 'json';
    level?: 'college' | 'lycee';
  };
}

interface GenerateResponse {
  content: string;
  format: string;
  metadata: {
    wordCount: number;
    sources: string[];
    generatedAt: string;
  };
}
```

### Prompts de g√©n√©ration

#### R√©sum√©

```
R√©sume le document suivant en {length} points cl√©s.
Format : liste √† puces avec titres.
Niveau : {level}

Document :
{content}
```

#### Fiche r√©vision

```
Cr√©e une fiche de r√©vision sur "{topic}" √† partir des sources.

Structure attendue :
1. ESSENTIEL (3-5 points cl√©s)
2. D√âFINITIONS (termes importants)
3. EXEMPLES (concrets, m√©morisables)
4. √Ä RETENIR (formules, dates, noms)
5. PI√àGES √Ä √âVITER (erreurs fr√©quentes)

Sources :
{documents}
```

#### Quiz

```
G√©n√®re un quiz de {count} questions sur "{topic}".

Format JSON :
{
  "questions": [
    {
      "question": "...",
      "type": "qcm" | "vrai_faux" | "reponse_courte",
      "options": ["A", "B", "C", "D"], // si QCM
      "answer": "...",
      "explanation": "..."
    }
  ]
}

Niveau de difficult√© : {level}
Sources : {documents}
```

---

## üìö RAG (Retrieval-Augmented Generation)

### Architecture

```
Documents (PDF, DOCX, MD)
        ‚Üì
[Parser + Chunking]
        ‚Üì
[Embeddings OpenAI]
        ‚Üì
[Stockage pgvector (Vercel Postgres)]
        ‚Üì
Recherche vectorielle
        ‚Üì
Contexte pour LLM
```

### Configuration embeddings

```typescript
// src/lib/ai/embeddings.ts
const embeddingsConfig = {
  model: 'text-embedding-3-small', // OpenAI
  dimensions: 1536,
  chunkSize: 500,    // tokens par chunk
  chunkOverlap: 50,  // chevauchement
};
```

### Table PostgreSQL (pgvector)

```sql
CREATE TABLE document_chunks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  content TEXT NOT NULL,
  embedding VECTOR(1536),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Index pour recherche vectorielle
CREATE INDEX ON document_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### Fonction de recherche

```typescript
// src/lib/ai/search.ts
async function searchDocuments(
  query: string,
  options: {
    subjectId?: string;
    themeId?: string;
    limit?: number;
    threshold?: number;
  }
): Promise<SearchResult[]> {
  // 1. Embed la query
  const queryEmbedding = await embedText(query);
  
  // 2. Recherche vectorielle
  const { data } = await prisma.\('match_documents', {
    query_embedding: queryEmbedding,
    match_threshold: options.threshold || 0.7,
    match_count: options.limit || 5,
    filter_subject: options.subjectId,
    filter_theme: options.themeId,
  });
  
  return data;
}
```

---

## üéì IA Professeur

### Fonctionnalit√©s

| Action | Description |
| :--- | :--- |
| **Analyse progression** | D√©tecte les √©l√®ves en difficult√© |
| **Suggestions p√©dagogiques** | Recommandations personnalis√©es |
| **G√©n√©ration exercices** | Cr√©er des exercices adapt√©s |
| **Correction assist√©e** | Aide √† l'√©valuation |

### Prompt analyse classe

```
Tu es un assistant p√©dagogique pour enseignants.

Analyse les donn√©es de progression de la classe et fournis :
1. ALERTES : √âl√®ves en difficult√© (progression < 50%)
2. TENDANCES : Points forts/faibles de la classe
3. RECOMMANDATIONS : Actions p√©dagogiques sugg√©r√©es

Donn√©es classe :
{classData}

Format : Liste structur√©e avec justifications.
```

---

## üõ°Ô∏è S√©curit√© & Limites

### Rate limiting

```typescript
const rateLimits = {
  student: {
    chatMessagesPerDay: 100,
    generationsPerDay: 20,
    documentsPerMonth: 50,
  },
  teacher: {
    chatMessagesPerDay: 200,
    generationsPerDay: 50,
    documentsPerMonth: 200,
  },
};
```

### Mod√©ration

```typescript
// POST /api/ai/chat - Middleware
async function moderateInput(message: string): Promise<boolean> {
  const response = await openai.moderations.create({
    input: message,
  });
  
  return !response.results[0].flagged;
}
```

### Filtrage contenu

- Pas de r√©ponses sur sujets non √©ducatifs
- Pas de g√©n√©ration de code malveillant
- Pas de contenu inappropri√© pour mineurs
- Logs des conversations pour audit

---

## üì¶ D√©pendances

```json
{
  "ai": "^4.0.0",           // Vercel AI SDK
  "@ai-sdk/openai": "^1.0.0",
  "openai": "^4.0.0",       // Pour embeddings
  "pdf-parse": "^1.1.1",    // Parser PDF
  "mammoth": "^1.6.0"       // Parser DOCX
}
```

---

## ‚úÖ Checklist

- [ ] Vercel AI SDK configur√©
- [ ] Cl√© OpenAI dans `.env`
- [ ] Table `document_chunks` cr√©√©e avec pgvector
- [ ] Fonction RPC `match_documents` cr√©√©e
- [ ] Rate limiting impl√©ment√©
- [ ] Mod√©ration activ√©e
- [ ] Prompts test√©s et optimis√©s
- [ ] Streaming activ√© pour le chat
